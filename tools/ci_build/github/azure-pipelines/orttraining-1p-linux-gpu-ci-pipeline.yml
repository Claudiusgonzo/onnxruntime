parameters:
  - name: conda_version
    displayName: Conda Version
    type: string
    default: 4.8.0

stages:
- stage: Python_Packaging

  variables:
    actual_extra_build_py_parameters: >
      --enable_training
      --wheel_name_suffix training
    docker_image_prefix: onnxruntime-training
    linux_gpu_dockerfile: Dockerfile.ubuntu_gpu
    python.version: 3.6
    BuildCommand: >
      tools/ci_build/github/linux/run_dockerbuild.sh
      -o ubuntu16.04 -d gpu -r $(Build.BinariesDirectory)
      -x "
      --enable_training
      --config $(buildConfig)
      --skip_onnx_tests
      --build_wheel
      --enable_nvtx_profile
      "
  jobs:
  - job: Linux_py_GPU_Wheels
    timeoutInMinutes: 0
    workspace:
      clean: all
    pool: Linux-GPU-CUDA10
    strategy: 
      maxParallel: 2
      matrix:
        Debug:
          buildConfig: Debug
        Release:
          buildConfig: Release
    steps:
      - checkout: self
        clean: true
        submodules: recursive

      # - template: templates/set-py-packaging-variables-step.yml

      # - task: CmdLine@2
      #   inputs:
      #     script: |
      #       sudo docker build \
      #         --pull \
      #         -t ${{ variables.docker_image_prefix }}-manylinux-gpu-$(python.version) \
      #         --build-arg BUILD_USER=onnxruntimedev \
      #         --build-arg BUILD_UID=$(id -u) \
      #         --build-arg PYTHON_VERSION=$(python.version) \
      #         --build-arg BUILD_EXTR_PAR="${{ variables.actual_extra_build_py_parameters }}" \
      #         --build-arg CONDA_VERSION="${{ parameters.conda_version }}" \
      #         -f ${{ variables.linux_gpu_dockerfile }} .
      #     workingDirectory: $(Build.SourcesDirectory)/tools/ci_build/github/linux/docker

      #  - task: CmdLine@2
      #   inputs:
      #     script: |
      #       sudo --preserve-env docker run \
      #         --gpus all \
      #         --rm \
      #         --volume $(Build.SourcesDirectory):/onnxruntime_src \
      #         --volume $(Build.BinariesDirectory):/build \
      #         --volume /data/models:/build/models:ro \
      #         -e NVIDIA_VISIBLE_DEVICES=all \
      #         -e NIGHTLY_BUILD \
      #         -e BUILD_BUILDNUMBER \
      #         ${{ variables.docker_image_prefix }}-manylinux-gpu-$(python.version) \
      #         $(python.manylinux.dir)/bin/python3 /onnxruntime_src/tools/ci_build/build.py \
      #           --build_dir /build \
      #           --config Release \
      #           --cmake_extra_defines PYTHON_INCLUDE_DIR=$(python.manylinux.include.dir) PYTHON_LIBRARY=/usr/lib64/librt.so \
      #           --skip_submodule_sync \
      #           --parallel \
      #           --build_wheel \
      #           --enable_onnx_tests \
      #           --use_cuda --cuda_version=10.1 --cuda_home=/usr/local/cuda-10.1 --cudnn_home=/usr/local/cuda-10.1 \
      #           ${{ variables.actual_extra_build_py_parameters }}
      #     workingDirectory: $(Build.SourcesDirectory)
      - script: ${{ variables.BuildCommand }}
        displayName: 'Command Line Script'

      - task: AzureKeyVault@1
        inputs:
          azureSubscription: 'AIInfraBuild'
          KeyVaultName: 'jingywatest'
          SecretsFilter: '*'
          RunAsPreJob: false

      - task: CmdLine@2
        inputs:
          script: |
            echo $(DockerPassword) > password.txt
            cat password.txt | docker login --username jingywatest --password-stdin jingywatest.azurecr.io
            docker tag onnxruntime-ubuntu16.04-cuda10.1-cudnn7.6 jingywatest.azurecr.io/test/onnxruntime-training-1p:$(Build.BuildId)
            docker push jingywatest.azurecr.io/test/onnxruntime-training-1p:$(Build.BuildId)

      - task: CopyFiles@2
        displayName: 'Copy Python Wheel to:  $(Build.ArtifactStagingDirectory)'
        inputs:
          SourceFolder: '$(Build.BinariesDirectory)'
          Contents: 'Release/dist/*.whl'
          TargetFolder: '$(Build.ArtifactStagingDirectory)'

      - task: PublishBuildArtifacts@1
        displayName: 'Publish Artifact: ONNXRuntime python wheel'
        inputs:
          ArtifactName: onnxruntime_gpu_1p

      - template: templates/component-governance-component-detection-steps.yml

      - template: templates/clean-agent-build-directory-step.yml
